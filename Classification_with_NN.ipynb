{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hacettepe University\n",
    "\n",
    "#### Artificial Intelligence Engineering Department\n",
    "\n",
    "#### Name - Surname :  Mehmet Alperen Ozcelik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Monkey Species using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_images(folderName, size):\n",
    "    \n",
    "    imageList = []\n",
    "    nameList = []\n",
    "    \n",
    "    for filename in os.listdir(folderName):\n",
    "        img = cv2.imread(os.path.join(folderName, filename))\n",
    "        \n",
    "        if img is not None:\n",
    "\n",
    "            resized = cv2.resize(img,size, interpolation= cv2.INTER_LINEAR)\n",
    "            image = resized.astype('float32')\n",
    "            image = image / 255\n",
    "            imageList.append(image)\n",
    "            nameList.append(filename[1])\n",
    "    \n",
    "    return imageList, nameList\n",
    "\n",
    "def all_images(mainFolder,size):\n",
    "    \n",
    "    imageList = []\n",
    "    specyList = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        img, specy = load_images(mainFolder + str(i), size)\n",
    "        imageList.extend(img)\n",
    "        specyList.extend(specy)\n",
    "        \n",
    "    imageList = np.array(imageList)\n",
    "    specyList = np.array(specyList)\n",
    "    \n",
    "    return imageList, specyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,species =  all_images(\"training/n\", (8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a,b = [],[]\n",
    "(unique, counts) = np.unique(species, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "for i in frequencies:\n",
    "    a.append(i[0])\n",
    "    b.append(int(i[1]))\n",
    "    \n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(a, b, color='red',alpha = 0.6)\n",
    "\n",
    "plt.xlabel(\"Number of Images\")\n",
    "plt.ylabel(\"Species\")\n",
    "plt.title(\"Distribution of Species\", size = 20)\n",
    "plt.xlim([100, 125])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images.reshape(1098,8*8*3)\n",
    "y = species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.10, random_state = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #Multi Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MultiLayerNN(BaseEstimator):\n",
    "\n",
    "    def __init__(self, X_train, Y_train, X_val, Y_val, num_of_layers, layer_size):\n",
    "\n",
    "        self.X_train = np.concatenate((X_train, np.ones((X_train.shape[0], 1))), axis=1)\n",
    "        self.Y_train = np.squeeze(np.eye(10)[Y_train.astype(np.int).reshape(-1)])\n",
    "        self.X_val = np.concatenate((X_val, np.ones((X_val.shape[0], 1))), axis=1)\n",
    "        self.Y_val = np.squeeze(np.eye(10)[Y_val.astype(np.int).reshape(-1)])\n",
    "        self.layer_length = num_of_layers\n",
    "        self.input_size = layer_size\n",
    "        self.layer = np.array([self.X_train.shape[1]] + [layer_size] * num_of_layers + [self.Y_train.shape[1]])\n",
    "        self.weights()\n",
    "\n",
    "    def weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        for i in range(self.layer.shape[0] - 1):\n",
    "            self.weights.append(np.random.uniform(-1, 1, size=[self.layer[i], self.layer[i + 1]]))\n",
    "        self.weights = np.asarray(self.weights)\n",
    "\n",
    "    def layers(self, batch_size):\n",
    "\n",
    "        self.h = [np.empty((batch_size, layer)) for layer in self.layer]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "\n",
    "        sgm = 1.0 / (1.0 + np.exp(-x))\n",
    "        return sgm\n",
    "\n",
    "    def sigmoid_prime(self, h):\n",
    "\n",
    "        sgm_pr = h * (1 - h)\n",
    "        return sgm_pr\n",
    "\n",
    "    def softmax(self, x):\n",
    "\n",
    "        softmax = np.exp(x) / np.exp(x).sum(axis=1, keepdims=True)\n",
    "        return softmax\n",
    "\n",
    "    def loss_function(self, y_pred, y):\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            difference = y[i] - y_pred[i]\n",
    "            squared_difference = difference ** 2\n",
    "            summation = summation + squared_difference\n",
    "\n",
    "        MSE = summation / len(y)\n",
    "        return MSE\n",
    "\n",
    "    def forward_propagation(self, b):\n",
    "\n",
    "        temp = b\n",
    "        self.h[0] = temp\n",
    "        for i, weights in enumerate(self.weights):\n",
    "            temp = self.sigmoid(temp.dot(weights))\n",
    "            self.h[i + 1] = temp\n",
    "        self.out = self.softmax(self.h[-1])\n",
    "\n",
    "    def back_propagation(self, y_batch):\n",
    "\n",
    "        delta_t = (self.out - y_batch) * self.sigmoid_prime(self.h[-1])\n",
    "        for i in range(1, len(self.weights) + 1):\n",
    "            self.weights[-i] -= self.learning_rate * (self.h[-i - 1].T.dot(delta_t)) / self.batch_size\n",
    "            delta_t = self.sigmoid_prime(self.h[-i - 1]) * (delta_t.dot(self.weights[-i].T))\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "        self.layers(X.shape[0])\n",
    "        self.forward_propagation(X)\n",
    "        categorical = np.zeros((self.out.shape[0], self.Y_train.shape[1]))\n",
    "        categorical[np.arange(self.out.shape[0]), self.out.argmax(axis=1)] = 1\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(len(categorical)):\n",
    "            for j in range(10):\n",
    "                if categorical[i][j] == 1:\n",
    "                    predictions.append(str(j))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def train(self, batch_size, epochs, learning_rate):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        for i in range(epochs):\n",
    "\n",
    "            self.layers(self.batch_size)\n",
    "            rand = np.random.permutation(self.X_train.shape[0])\n",
    "\n",
    "            X_batches = np.array_split(self.X_train[rand], self.X_train.shape[0] / self.batch_size)\n",
    "            Y_batches = np.array_split(self.Y_train[rand], self.X_train.shape[0] / self.batch_size)\n",
    "\n",
    "            for x_batch, y_batch in zip(X_batches, Y_batches):\n",
    "                self.forward_propagation(x_batch)\n",
    "                self.back_propagation(y_batch)\n",
    "\n",
    "            self.layers(self.X_val.shape[0])\n",
    "            self.forward_propagation(self.X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change of Layer Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Layers: 1 Accuracy: 0.33636363636363636\n",
      "Number of Layers: 2 Accuracy: 0.37272727272727274\n",
      "Number of Layers: 3 Accuracy: 0.43636363636363634\n",
      "Number of Layers: 4 Accuracy: 0.41818181818181815\n",
      "Number of Layers: 5 Accuracy: 0.37272727272727274\n",
      "Number of Layers: 6 Accuracy: 0.37272727272727274\n",
      "Number of Layers: 7 Accuracy: 0.11818181818181818\n",
      "Number of Layers: 8 Accuracy: 0.39090909090909093\n",
      "Number of Layers: 9 Accuracy: 0.07272727272727272\n",
      "Number of Layers: 10 Accuracy: 0.13636363636363635\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    model = MultiLayerNN(X_train,y_train,X_test, y_test, num_of_layers = i, layer_size = 128)\n",
    "    model.train(batch_size=64, epochs=50, learning_rate=0.5)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(\"Number of Layers:\",i,\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  > I decided to use 5 Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change of Batch Size and Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  > While my learning rates are between 0.005 and 0.02, since the accuracy is very low, I decided to increase it in these intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 16 Learning Rate: 0.10 Accuracy: 0.25\n",
      "Batch Size: 16 Learning Rate: 0.20 Accuracy: 0.47\n",
      "Batch Size: 16 Learning Rate: 0.30 Accuracy: 0.43\n",
      "Batch Size: 16 Learning Rate: 0.40 Accuracy: 0.46\n",
      "Batch Size: 16 Learning Rate: 0.50 Accuracy: 0.10\n",
      "Batch Size: 16 Learning Rate: 0.60 Accuracy: 0.46\n",
      "Batch Size: 16 Learning Rate: 0.70 Accuracy: 0.35\n",
      "Batch Size: 16 Learning Rate: 0.80 Accuracy: 0.20\n",
      "Batch Size: 16 Learning Rate: 0.90 Accuracy: 0.42\n",
      "Batch Size: 16 Learning Rate: 1.00 Accuracy: 0.35\n",
      "Batch Size: 32 Learning Rate: 0.10 Accuracy: 0.34\n",
      "Batch Size: 32 Learning Rate: 0.20 Accuracy: 0.35\n",
      "Batch Size: 32 Learning Rate: 0.30 Accuracy: 0.39\n",
      "Batch Size: 32 Learning Rate: 0.40 Accuracy: 0.40\n",
      "Batch Size: 32 Learning Rate: 0.50 Accuracy: 0.51\n",
      "Batch Size: 32 Learning Rate: 0.60 Accuracy: 0.50\n",
      "Batch Size: 32 Learning Rate: 0.70 Accuracy: 0.30\n",
      "Batch Size: 32 Learning Rate: 0.80 Accuracy: 0.50\n",
      "Batch Size: 32 Learning Rate: 0.90 Accuracy: 0.41\n",
      "Batch Size: 32 Learning Rate: 1.00 Accuracy: 0.45\n",
      "Batch Size: 64 Learning Rate: 0.10 Accuracy: 0.14\n",
      "Batch Size: 64 Learning Rate: 0.20 Accuracy: 0.15\n",
      "Batch Size: 64 Learning Rate: 0.30 Accuracy: 0.33\n",
      "Batch Size: 64 Learning Rate: 0.40 Accuracy: 0.36\n",
      "Batch Size: 64 Learning Rate: 0.50 Accuracy: 0.15\n",
      "Batch Size: 64 Learning Rate: 0.60 Accuracy: 0.42\n",
      "Batch Size: 64 Learning Rate: 0.70 Accuracy: 0.15\n",
      "Batch Size: 64 Learning Rate: 0.80 Accuracy: 0.41\n",
      "Batch Size: 64 Learning Rate: 0.90 Accuracy: 0.26\n",
      "Batch Size: 64 Learning Rate: 1.00 Accuracy: 0.15\n",
      "Batch Size: 128 Learning Rate: 0.10 Accuracy: 0.05\n",
      "Batch Size: 128 Learning Rate: 0.20 Accuracy: 0.26\n",
      "Batch Size: 128 Learning Rate: 0.30 Accuracy: 0.35\n",
      "Batch Size: 128 Learning Rate: 0.40 Accuracy: 0.15\n",
      "Batch Size: 128 Learning Rate: 0.50 Accuracy: 0.41\n",
      "Batch Size: 128 Learning Rate: 0.60 Accuracy: 0.30\n",
      "Batch Size: 128 Learning Rate: 0.70 Accuracy: 0.14\n",
      "Batch Size: 128 Learning Rate: 0.80 Accuracy: 0.40\n",
      "Batch Size: 128 Learning Rate: 0.90 Accuracy: 0.26\n",
      "Batch Size: 128 Learning Rate: 1.00 Accuracy: 0.07\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,8):\n",
    "    for j in range(10):\n",
    "        model = MultiLayerNN(X_train,y_train,X_test, y_test, num_of_layers = 5, layer_size = 128)\n",
    "        model.train(batch_size=2**i, epochs=50, learning_rate=0.1+(j*0.1))\n",
    "        pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        print(\"Batch Size:\",2**i,\"Learning Rate: %.2f\" %(0.1+(j*0.1)),\"Accuracy: %.2f\" %acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a result, I decided that the best batch size is 32 and the best learning rate is 0.5 in my Multi Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,species =  all_images(\"training/n\", (32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images\n",
    "y = species.reshape(len(y), 1)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=10, dtype=\"int\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.20, random_state = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a result of my experiments in the code, I decided to use 32 as the number of units and (3,3) as the width and height value. I can't show these attempts because they all take about 2 hours to run :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(activation_func, learning_rate, number_of_units = 32, width_and_height = (3,3)):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(number_of_units, width_and_height, activation = activation_func, kernel_initializer = 'he_uniform', padding= 'same', input_shape=(32, 32, 3)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = SGD(lr = learning_rate, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change of Batch Size and Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 16 Learning Rate: 0.05 Accuracy: 0.58\n",
      "Batch Size: 16 Learning Rate: 0.15 Accuracy: 0.52\n",
      "Batch Size: 16 Learning Rate: 0.25 Accuracy: 0.54\n",
      "Batch Size: 16 Learning Rate: 0.35 Accuracy: 0.50\n",
      "Batch Size: 16 Learning Rate: 0.45 Accuracy: 0.50\n",
      "Batch Size: 32 Learning Rate: 0.05 Accuracy: 0.61\n",
      "Batch Size: 32 Learning Rate: 0.15 Accuracy: 0.60\n",
      "Batch Size: 32 Learning Rate: 0.25 Accuracy: 0.56\n",
      "Batch Size: 32 Learning Rate: 0.35 Accuracy: 0.57\n",
      "Batch Size: 32 Learning Rate: 0.45 Accuracy: 0.55\n",
      "Batch Size: 64 Learning Rate: 0.05 Accuracy: 0.55\n",
      "Batch Size: 64 Learning Rate: 0.15 Accuracy: 0.59\n",
      "Batch Size: 64 Learning Rate: 0.25 Accuracy: 0.56\n",
      "Batch Size: 64 Learning Rate: 0.35 Accuracy: 0.56\n",
      "Batch Size: 64 Learning Rate: 0.45 Accuracy: 0.45\n",
      "Batch Size: 128 Learning Rate: 0.05 Accuracy: 0.55\n",
      "Batch Size: 128 Learning Rate: 0.15 Accuracy: 0.56\n",
      "Batch Size: 128 Learning Rate: 0.25 Accuracy: 0.59\n",
      "Batch Size: 128 Learning Rate: 0.35 Accuracy: 0.55\n",
      "Batch Size: 128 Learning Rate: 0.45 Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,8):\n",
    "    for j in range(5):\n",
    "        model = CNN('relu', (0.01 + 0.005*j)) \n",
    "        fit = model.fit(X_train, y_train, epochs=30, batch_size=2**i, verbose=0)\n",
    "        _, acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "        print(\"Batch Size:\",2**i,\"Learning Rate: %.2f\" %(0.05+(j*0.1)),\"Accuracy: %.2f\" %acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a result, I decided that the best batch size is 32 and the best learning rate is 0.05 in Single Convolutional Layer CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change of Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Function: sigmoid Accuracy: 0.31\n",
      "Activation Function: relu Accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if i == 1:\n",
    "        x = 'relu'\n",
    "    else:\n",
    "        x = 'sigmoid'\n",
    "    model = CNN(x, (0.01)) \n",
    "    fit = model.fit(X_train, y_train, epochs=30, batch_size=64, verbose=0)\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    print(\"Activation Function:\",x, \"Accuracy: %.2f\" %acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I decided to use ReLu function as an activation function in Single Convolutional Layer CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Convolutional Layers and Two Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN2(activation_func, learning_rate, number_of_units = 32, width_and_height = (3,3)):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(number_of_units, width_and_height, activation = activation_func, kernel_initializer = 'he_uniform', padding= 'same', input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Conv2D(number_of_units, width_and_height, activation = activation_func, kernel_initializer = 'he_uniform', padding= 'same'))\n",
    "    model.add(MaxPooling2D(1,1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = SGD(lr = learning_rate, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change of Batch Size and Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 16 Learning Rate: 0.05 Accuracy: 0.59\n",
      "Batch Size: 16 Learning Rate: 0.15 Accuracy: 0.57\n",
      "Batch Size: 16 Learning Rate: 0.25 Accuracy: 0.49\n",
      "Batch Size: 16 Learning Rate: 0.35 Accuracy: 0.40\n",
      "Batch Size: 16 Learning Rate: 0.45 Accuracy: 0.37\n",
      "Batch Size: 32 Learning Rate: 0.05 Accuracy: 0.60\n",
      "Batch Size: 32 Learning Rate: 0.15 Accuracy: 0.58\n",
      "Batch Size: 32 Learning Rate: 0.25 Accuracy: 0.59\n",
      "Batch Size: 32 Learning Rate: 0.35 Accuracy: 0.57\n",
      "Batch Size: 32 Learning Rate: 0.45 Accuracy: 0.53\n",
      "Batch Size: 64 Learning Rate: 0.05 Accuracy: 0.64\n",
      "Batch Size: 64 Learning Rate: 0.15 Accuracy: 0.61\n",
      "Batch Size: 64 Learning Rate: 0.25 Accuracy: 0.58\n",
      "Batch Size: 64 Learning Rate: 0.35 Accuracy: 0.57\n",
      "Batch Size: 64 Learning Rate: 0.45 Accuracy: 0.58\n",
      "Batch Size: 128 Learning Rate: 0.05 Accuracy: 0.59\n",
      "Batch Size: 128 Learning Rate: 0.15 Accuracy: 0.61\n",
      "Batch Size: 128 Learning Rate: 0.25 Accuracy: 0.59\n",
      "Batch Size: 128 Learning Rate: 0.35 Accuracy: 0.58\n",
      "Batch Size: 128 Learning Rate: 0.45 Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,8):\n",
    "    for j in range(5):\n",
    "        model = CNN2('relu', (0.01 + 0.005*j)) \n",
    "        fit = model.fit(X_train, y_train, epochs=30, batch_size=2**i, verbose=0)\n",
    "        _, acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "        print(\"Batch Size:\",2**i,\"Learning Rate: %.2f\" %(0.05+(j*0.1)),\"Accuracy: %.2f\" %acc)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a result, I decided that the best batch size is 64 and the best learning rate is 0.05 in Two Convolutional Layers and Two Fully Connected Layers CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change of Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Function: sigmoid Accuracy: 0.30\n",
      "Activation Function: relu Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if i == 1:\n",
    "        x = 'relu'\n",
    "    else:\n",
    "        x = 'sigmoid'\n",
    "    model = CNN2(x, 0.05) \n",
    "    fit = model.fit(X_train, y_train, epochs=30, batch_size=64, verbose=0)\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    print(\"Activation Function:\",x, \"Accuracy: %.2f\" %acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I decided to use ReLu function as an activation function in  Two Convolutional Layers and Two Fully Connected Layers CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Factors such as learning rate, batch size, number of layers change the model a lot, but I was surprised that the accuracy values that appear as we run the model again are extremely different, perhaps I may not have been able to use the right models for this data.\n",
    "\n",
    "###### At the same time, although it seems that there are 6-7 parameters, it takes a very long time and patience to find the most optimal value of the combination of all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
